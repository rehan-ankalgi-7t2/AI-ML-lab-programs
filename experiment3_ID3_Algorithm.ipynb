{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "data = pd.read_csv(\"Weather.csv\")\n",
    "data_size = len(data)\n",
    "treenodes = []\n",
    "tree = {\n",
    "    \"ROOT\": data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_entropy(data, col):\n",
    "    mydict = {}\n",
    "    for elem in data[col]:\n",
    "        if elem in mydict.keys():\n",
    "            mydict[elem] += 1\n",
    "        else:\n",
    "            mydict[elem] = 1\n",
    "\n",
    "    total = sum(mydict.values())\n",
    "    E = 0\n",
    "\n",
    "    for key in mydict.keys():\n",
    "        E += entropy(mydict[key], total)\n",
    "    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(num, denom):\n",
    "    return -(num/denom)*np.log2(num/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_data(data, column):\n",
    "    sort = {}\n",
    "\n",
    "    for column_name in get_attributes(data, column):\n",
    "        sort[column_name] = data.loc[data[column] == column_name]\n",
    "\n",
    "    return sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(data, column):\n",
    "    return data[column].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(total_entropy, sorted_data, entropy_by_attribute):\n",
    "    length = data_size\n",
    "    total = 0\n",
    "    for col, df in sorted_data.items():\n",
    "        total += (len(df)/length)*entropy_by_attribute[col]\n",
    "\n",
    "    return total_entropy - total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy_by_attribute(sorted_data):\n",
    "    entropies ={}\n",
    "    for key, df in sorted_data.items():\n",
    "        entropies[key] = total_entropy(df, 'Decision')\n",
    "\n",
    "    return entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_node(data, column):\n",
    "    return data.drop(column, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(tree):\n",
    "    for branch, data in tree.items():\n",
    "    # Make sure it's a DataFrame\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            continue\n",
    "        #Fetch column names so you can use them to iterate later\n",
    "        columns = data.columns\n",
    "        # Calculate the Entropy for the entire dataset\n",
    "        total_entropy_for_data = total_entropy(data.values, -1)\n",
    "        # If only one column is left, it means we're done.\n",
    "        if len(columns) == 1:\n",
    "            break\n",
    "        # Keep track of information gain to choose the attribute with maximum info gain. \n",
    "        info_gain_list = []\n",
    "        # Now iterate over each column to calculate information gain w.r.t o/p column\n",
    "        \n",
    "    for i in range(0, len(data.columns)-1):\n",
    "        sorted_rows = get_sorted_data(data, columns[i])\n",
    "        # Calculate the entropy w.r.t to each attribute based on sorted columns\n",
    "        entropy_by_attribute = get_entropy_by_attribute(sorted_rows)\n",
    "        # get the info gain\n",
    "        info_gain = info_gain(total_entropy_for_data, sorted_rows, entropy_by_attribute)\n",
    "        # save it\n",
    "        info_gain_list.append(info_gain)\n",
    "        # Find index of max info gain\n",
    "        node = info_gain_list.index(max(info_gain_list))\n",
    "        # sort the data into branches based on the new node\n",
    "        branches = get_sorted_data(data, columns[node])\n",
    "        # If we've reached the end of iterations, just assign the value, else drop the sorted column\n",
    "    \n",
    "    for attr, df in branches.items():\n",
    "        if (total_entropy(df, columns[-1]) == 0):\n",
    "            branches[attr] = df.iloc[0,-1]\n",
    "        else:\n",
    "            branches[attr] = df.drop(columns[node], axis=1)\n",
    "            # Keep track of nodes already done\n",
    "            treenodes.append(columns[node])\n",
    "            # add the new branches to the tree\n",
    "            child = {columns[node]: {}}\n",
    "            tree[branch] = child\n",
    "            tree[branch][columns[node]] = branches\n",
    "            # ID3\n",
    "            id3(tree[branch][columns[node]])\n",
    "            x = id3(tree)\n",
    "            pprint(tree, depth=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "535e7dfa4e79b8a16ee5958c03c29abfca9eab7a4cbaa00a7baba8beca86875c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
